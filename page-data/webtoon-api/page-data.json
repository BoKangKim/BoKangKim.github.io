{
    "componentChunkName": "component---src-templates-markdown-layout-tsx",
    "path": "/webtoon-api/",
    "result": {"data":{"markdownRemark":{"html":"<h2>크롤링</h2>\n<p>크롤링은 웹 페이지에서 데이터를 추출해 내는 행위입니다.</p>\n<p>저는 보통 API를 만들거나 Tensorflow 학습데이터를 수집하는데 자주 이용합니다.\r\n<br>이번 포스트에서 다룰 내용은 정말 단순히 Node.js에서 크롤링하는 기초적인 방법만을 다룰것이며 단순 정보를 긁어오는 것은 매우 쉽습니다.</p>\n<p>실제 크롤링을 통해 무언가를 하려면 크롤링할 대상의 URL 규칙성, 페이지의 구조 등을 직접 분석해보면서 코드를 짜는 방법을 고민해 보셔야 합니다.</p>\n<p>또한 크롤링은 사람이 직접 데이터를 수집하는것보다 훨씬 빠른속도로 서버에 다수에 요청을 보내서 데이터를 응답받기 때문에 크롤링 대상 서버에 문제를 발생시킬수 있습니다.\r\n<br>위와 같은 이유로 크롤링이 차단되어 있는 사이트들도 있으니 크롤링이 허용되어있는 사이트인지 확인하는것도 중요합니다.</p>\n<h2>크롤링 도구 선택</h2>\n<p>크롤링에 활용가능한 도구는 Jsoup(Java), BeautifulSoup(Python)등 개발 언어마다 여러 종류가 있습니다.\r\n<br>저는 그중 저에게 가장 편한 node.js 도구들을 이용하겠습니다.</p>\n<p>node.js에서도 크롤링에 사용할수 있는 도구도 종류가 많고 그중에 용도에 맞는 도구를 선택하면 되겠습니다.\r\n이번에 크롤링 대상 페이지는 연습하기 좋은 <a href=\"https://news.naver.com/main/list.naver?mode=LSD&#x26;mid=sec&#x26;sid1=001\">네이버 뉴스 속보</a> 그중에서도 1페이지만 가져오도록 해보겠습니다.\r\n해당 페이지는 로그인도 필요없고 따로 크롤링이 차단되어있지도 않기때문에 단순 http 라이브러리와 parsing 라이브러리만 사용하겠습니다.</p>\n<p>⚠ http 라이브러리나 parsing 라이브러리 둘다 크롤링에 활용 가능한 도구이지 '크롤링만을 위한 도구'가 아닙니다.<br> 해당 라이브러리가 어떤곳에 쓰이는지 공부해 보는것도 좋을것 같습니다.</p>\n<p>만약 특정이유로 사람이 직접 데이터를 수집하는 것처럼 브라우저를 핸들링해 크롤링해야 한다면 속도는 느리지만 Chromium을 제어하는 도구들(Puppeteer등)을 사용하면 되겠습니다.</p>\n<ul>\n<li>HTTP 라이브러리: Axios\n<ul>\n<li>http 라이브러리에는 종류가 굉장히 많고 저는 평소 Request를 자주 사용해 왔는데 해당 라이브러리가 deprecated 되었다는 소식을 듣고 이번에는 가장 성능이 좋다는 Axios를 사용해 보기로 했습니다.</li>\n</ul>\n</li>\n<li>Parsing 라이브러리: Cheerio\n<ul>\n<li>사실 parsing 라이브러리는 없어도 직접 파싱해서 사용할수 있지만 방대한 량의 html코드를 파싱하는 과정이 복잡해질뿐더러 코드의 가독성도 떨어집니다.\r\n<br>저는 여기서 jQuery문법을 그대로 사용할 수 있는 Cheerio를 사용해서 파싱하겠습니다.</li>\n</ul>\n</li>\n</ul>\n<h2>개발환경 설정</h2>\n<h3>새 프로젝트 생성</h3>\n<deckgo-highlight-code language=\"bash\"  >\n          <code slot=\"code\">$ mkdir &lt;프로젝트 이름&gt;\r\n$ cd &lt;프로젝트 이름&gt;\r\n$ npm init</code>\n        </deckgo-highlight-code>\n<h3>사용할 node.js 모듈 설치</h3>\n<deckgo-highlight-code language=\"bash\"  >\n          <code slot=\"code\">npm install axios cheerio</code>\n        </deckgo-highlight-code>\n<h2>네이버 뉴스 속보 크롤링 코드 작성</h2>\n<h3>기본 코드 작성</h3>\n<deckgo-highlight-code language=\"javascript\"  >\n          <code slot=\"code\">const axios = require(&quot;axios&quot;);\r\nconst cheerio = require(&quot;cheerio&quot;);\r\n\r\n(async () =&gt; {\r\n  //크롤링 대상 URL, axios의 get은 비동기 함수이므로 async-await을 사용한다.\r\n  const html = await axios.get(&quot;https://news.naver.com/main/list.naver?mode=LSD&amp;mid=sec&amp;sid1=001&quot;),\r\n    $ = cheerio.load(html.data);\r\n})();</code>\n        </deckgo-highlight-code>\n<h3>원하는 정보의 Selector 가져오기</h3>\n<p>원하는 URL에서 정보들을 가져와 변수에 담는 코드는 작성했늬 이제 어떤 데이터를 가지고 올지 작성하는 코드를 작성해야 합니다.\r\n저는 여기서 뉴스의 이름정보를 가지고 오겠습니다.</p>\n<ul>\n<li>\n<p>해당 페이지에서 원하는 정보가 있는 element에 오른쪽마우스 클릭후 검사를 선택해 개발자 도구를 엽니다.\r\n<img src=\"https://user-images.githubusercontent.com/71566740/131453990-c0ee880e-34e5-400e-ab6c-7d21221596f0.png\" alt=\"capture1\"></p>\n</li>\n<li>\n<p>a태그의 text가 기사의 이름을 가지고 있으니 해당 태그의 Selector를 복사해줍니다.\r\n<img src=\"https://user-images.githubusercontent.com/71566740/131454264-60703bfa-5107-4200-9f55-cdd101171894.png\" alt=\"capture2\"></p>\n</li>\n</ul>\n<p>구조가 단순한 페이지에 경우엔 이런 방법으로 Selector를 쉽게 얻을수 있습니다.\r\n<br> 하지만 여러 Element가 겹처있고 페이지 구조가 복잡하다면 개발자 도구에서 직접 구조를 파악하는게 중요합니다.\r\n#main_content > div.list_body.newsflash_body > ul.type06_headline > li:nth-child(1) > dl > dt:nth-child(2) > a\r\n<br>하지만 얼마전 다음 웹툰이 카카오 웹툰으로 통합되면서 해당 방법으로 웹툰 정보를 받을수 없게 되었습니다.\r\n<br>네이버 웹툰의 정보는 원래 크롤링해서 사용했었는데 이번에 카카오 웹툰도 비슷한 방법으로 크롤링하는 코드를 작성하는겸 기초적인 Node.js 크롤링 방법을 공유해보려합니다.</p>\n<p><br>크롤링은 꼭 개발자가 아니더라도 원하는 데이터를 자급자족 할 수 있다는 점에서 활용도가 정말 높습니다.\r\n<br>하지만 실제 서비스를 위한 코드를 작성할때는 잘 알아보시고 사용하는게 좋습니다.\r\n<br>\r\n<br>이전에 토이 프로젝트로 네이버 웹툰, 다음 웹툰의 정보들을 한번에 검색할 수 있는 웹 어플리케이션을 만든적이 있는데 다음 웹툰은 특이하게\r\n개발자 도구로 네트워크 부분을 확인해보면 요청하고 응답하는 api 주소가 노출되어있어 외부 웹에서 해당 주소로 요청을 보내도 똑같이 응답받을수 있었습니다.</p>","frontmatter":{"emoji":"📢","title":"크롤링을 통한 데이터 수집","date":"2021-08-02","description":"node.js 기본적인 크롤링 방법을 공유합니다.","tag":["Javascript","Data"]},"fields":{"slug":"/webtoon-api/"},"id":"05b01142-66d6-5251-9e6b-cc1a5376282e"},"allMarkdownRemark":{"nodes":[{"fields":{"slug":"/copilot-review/"},"frontmatter":{"description":"Github의 코딩 AI Copilot을 한 달간 사용해본 경험을 공유합니다.","title":"Copilot 사용 후기"},"id":"8a284f98-aa79-5a11-9f60-17da05b03882"},{"fields":{"slug":"/typescript-express/"},"frontmatter":{"description":"Typescript를 이용한 Express 설정을 공유합니다.","title":"Typescript + Express 설정하기"},"id":"7de321b0-d894-5d5a-a7e1-058f7c309364"},{"fields":{"slug":"/blog-remake-review1/"},"frontmatter":{"description":"블로그를 다시 만들기 시작하면서 느낀점을 공유합니다.","title":"블로그 제작 중간 리뷰"},"id":"4cfa4a82-589b-5649-8fd0-5cbb6f48d40b"},{"fields":{"slug":"/webtoon-api/"},"frontmatter":{"description":"node.js 기본적인 크롤링 방법을 공유합니다.","title":"크롤링을 통한 데이터 수집"},"id":"05b01142-66d6-5251-9e6b-cc1a5376282e"},{"fields":{"slug":"/good-commit-message/"},"frontmatter":{"description":"커밋 메시지 작성 규칙을 공유합니다.","title":"좋은 커밋 메시지 작성하기"},"id":"98992a08-a70f-5f2e-b087-f3ddf6331f1d"}]}},"pageContext":{"slug":"/webtoon-api/"}},
    "staticQueryHashes": []}